\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{cite}

\title{Capitolo 1: Stato dell'Arte dei Protocolli di Comunicazione}
\author{}
\date{}

\begin{document}

\maketitle

\chapter{Stato dell'Arte dei Protocolli di Comunicazione}

\section{API REST (Representational State Transfer)}

\subsection{Principi Architetturali e Vincoli}

REST (Representational State Transfer) rappresenta uno stile architetturale introdotto da Roy Fielding nel 2000 nella sua dissertazione di dottorato, con l'obiettivo di rendere la progettazione delle interfacce web scalabile, semplice e resiliente. Un servizio RESTful non è un protocollo vero e proprio, ma piuttosto un insieme di vincoli architetturali applicabili tipicamente sopra il protocollo HTTP. La comprensione di questi vincoli è fondamentale per progettare API che siano effettivamente RESTful e non semplicemente basate su HTTP.\cite{fielding2000}

\subsubsection{I sei vincoli fondamentali dell'architettura REST}

\paragraph{Interfaccia Uniforme (Uniform Interface)}
Questo è il vincolo più caratterizzante di REST e si articola in quattro sotto-principi. Ogni risorsa nel sistema deve essere identificata tramite un URI (Uniform Resource Identifier) univoco e manipolata attraverso rappresentazioni standard, generalmente in formato JSON o XML. Le richieste e le risposte devono essere auto-descrittive, contenendo tutte le informazioni necessarie per comprendere come processare il messaggio. Inoltre, le risposte dovrebbero includere collegamenti hypermedia che guidano il client nelle azioni successive disponibili, un principio noto come HATEOAS (Hypermedia As The Engine Of Application State). Questo approccio permette al client di navigare dinamicamente l'API senza dover conoscere a priori la struttura completa degli endpoint.\cite{restapitutorial}

\paragraph{Separazione Client-Server (Client-Server Separation)}
L'architettura REST impone una netta separazione tra la logica di presentazione (client) e la gestione dei dati e della business logic (server). Questa separazione favorisce l'indipendenza evolutiva tra le componenti: il client può essere modificato o sostituito senza impattare il server e viceversa. Questo principio facilita anche la portabilità dell'interfaccia utente su diverse piattaforme e migliora la scalabilità permettendo ai componenti server di evolversi indipendentemente.\cite{restfulapi2024}

\paragraph{Statelessness (Assenza di Stato)}
Il server non mantiene alcun stato relativo alle sessioni client tra richieste successive. Ogni richiesta HTTP dal client al server deve contenere tutte le informazioni necessarie per essere compresa e processata autonomamente, inclusi parametri, autenticazione e contesto. Questo vincolo semplifica drasticamente l'implementazione del server, migliora l'affidabilità (non ci sono stati da sincronizzare in caso di fallimenti) e facilita la scalabilità orizzontale, poiché qualsiasi server può gestire qualsiasi richiesta senza dover recuperare informazioni di sessione.\cite{wikipedia-rest}

\paragraph{Cacheability (Memorizzabilità in Cache)}
Le risposte del server devono esplicitamente dichiarare se e per quanto tempo possono essere memorizzate in cache dai client o dagli intermediari. Questo si ottiene tipicamente attraverso header HTTP come Cache-Control, ETag e Last-Modified. La cache riduce il numero di interazioni client-server, diminuisce la latenza percepita dall'utente e migliora l'efficienza complessiva del sistema, riducendo il carico sul server.\cite{caching2024}

\paragraph{Layered System (Sistema a Livelli)}
L'architettura REST permette di inserire componenti intermediari tra client e server, come proxy, gateway e load balancer, senza che il client debba essere consapevole di comunicare con il server finale o con un intermediario. Ogni componente interagisce solo con il livello immediatamente adiacente. Questo favorisce la scalabilità attraverso il bilanciamento del carico, migliora la sicurezza attraverso gateway che possono implementare policy di accesso, e facilita l'implementazione di cache condivise.\cite{wikipedia-rest2}

\paragraph{Code on Demand (Codice su Richiesta) - Opzionale}
Questo è l'unico vincolo opzionale di REST. Permette al server di estendere temporaneamente la funzionalità del client inviando codice eseguibile, come script JavaScript o applet. Sebbene raramente implementato nelle API moderne, questo principio offre flessibilità nell'estendere le capacità del client senza richiedere aggiornamenti software completi.\cite{code-on-demand}

\subsection{Punti di Forza: Semplicità, Statelessness, Scalabilità}

\subsubsection{Semplicità e Intuitività}
REST si fonda sull'utilizzo dei metodi HTTP standard (GET per recuperare risorse, POST per crearle, PUT per aggiornarle completamente, PATCH per aggiornamenti parziali, DELETE per eliminarle) applicati a risorse identificate da URI leggibili e semanticamente significativi. Questa mappatura diretta tra operazioni CRUD (Create, Read, Update, Delete) e verbi HTTP rende l'interazione con le API RESTful estremamente intuitiva per gli sviluppatori. La curva di apprendimento è ridotta e la comprensione del comportamento del sistema è facilitata dalla semantica chiara delle operazioni. Inoltre, REST non richiede tooling specializzato: qualsiasi client HTTP può interagire con un'API REST, garantendo interoperabilità universale con sistemi eterogenei.\cite{microsoft-rest}

\subsubsection{Statelessness e i suoi Vantaggi}
L'assenza di stato sul server rappresenta uno dei vantaggi più significativi di REST. Ogni richiesta è completamente indipendente, il che significa che non è necessario mantenere informazioni di sessione sul server tra chiamate successive. Questo principio offre numerosi benefici pratici:\cite{arbisoft-stateless}

\begin{itemize}
\item \textbf{Scalabilità Orizzontale:} Poiché non esiste affinità di sessione, qualsiasi server in un cluster può gestire qualsiasi richiesta. Questo semplifica enormemente il bilanciamento del carico e permette di aggiungere o rimuovere server dinamicamente in base alla domanda.
\item \textbf{Affidabilità:} In caso di fallimento di un server, non si perdono informazioni di sessione critiche. Un altro server può immediatamente prendere in carico le richieste senza necessità di recupero dello stato.
\item \textbf{Semplicità di Implementazione:} Non è necessario implementare meccanismi complessi di gestione delle sessioni, sincronizzazione dello stato tra server o persistenza delle sessioni.
\item \textbf{Manutenibilità:} Gli aggiornamenti dei server possono essere effettuati con rolling updates senza preoccuparsi di migrare sessioni attive.
\end{itemize}

\subsubsection{Scalabilità}
La combinazione di statelessness, caching e architettura a livelli rende REST particolarmente adatto per sistemi che devono gestire milioni di utenti concorrenti. Giganti del web come Amazon, Google, Facebook e Twitter utilizzano API REST proprio per queste caratteristiche di scalabilità. I sistemi RESTful possono essere scalati orizzontalmente semplicemente aggiungendo più server dietro un load balancer, senza modifiche architetturali significative.\cite{ibm-rest}

La possibilità di implementare cache a diversi livelli (browser, CDN, reverse proxy, server) riduce drasticamente il carico sui server di backend e migliora i tempi di risposta. Secondo statistiche recenti, l'83-93\% delle API pubbliche utilizzano REST come architettura principale, testimonianza della sua efficacia in scenari di produzione su larga scala.\cite{api-statistics}

\subsection{Debolezze: Over-Fetching, Under-Fetching e Performance}

Nonostante i numerosi vantaggi, REST presenta alcune limitazioni intrinseche che possono impattare l'efficienza e le performance in determinati scenari.

\subsubsection{Over-Fetching}
L'over-fetching si verifica quando un endpoint REST restituisce più dati di quelli effettivamente necessari al client. Ad esempio, un endpoint \texttt{/api/users/123} potrebbe restituire tutti gli attributi dell'utente (nome, email, indirizzo, preferenze, cronologia ordini, ecc.) anche quando il client necessita solo del nome. Questo comporta:\cite{stackoverflow-overfetching}

\begin{itemize}
\item \textbf{Spreco di Banda:} Trasferimento di dati inutili sulla rete, particolarmente problematico per client mobili con connessioni limitate o costose.
\item \textbf{Performance Degradate:} Parsing e processing di dati non necessari sul client, con conseguente aumento della latenza percepita.
\item \textbf{Carico sul Server:} Il server deve recuperare, serializzare e trasmettere dati che non verranno utilizzati, sprecando risorse computazionali.
\end{itemize}

\subsubsection{Under-Fetching e il Problema N+1}
L'under-fetching è il problema complementare: un singolo endpoint non fornisce tutti i dati necessari al client, che deve quindi effettuare multiple richieste per ottenere informazioni complete. Un caso classico è il "problema N+1": per visualizzare una lista di N post con i relativi autori, il client deve prima richiedere la lista dei post (1 richiesta) e poi fare N richieste aggiuntive per ottenere i dettagli di ciascun autore.\cite{nplus1-problem}

Questo pattern genera:
\begin{itemize}
\item \textbf{Latenza Moltiplicata:} Ogni richiesta HTTP comporta overhead di rete (handshake TCP, SSL, header HTTP). Multiple richieste sequenziali amplificano drasticamente i tempi di risposta totali.
\item \textbf{Inefficienza:} Il rapporto tra dati utili trasferiti e overhead di protocollo peggiora significativamente.
\item \textbf{Complessità sul Client:} La logica per orchestrare multiple chiamate e aggregare i risultati diventa complessa e error-prone.
\end{itemize}

\subsection{Casi d'Uso Consolidati}

Le API REST hanno dimostrato la loro efficacia in un'ampia gamma di domini applicativi, diventando lo standard de facto per l'integrazione di sistemi moderni.

\subsubsection{Applicazioni Web e Mobile}
Social network come Twitter e Facebook espongono le loro funzionalità attraverso API REST, permettendo a sviluppatori terzi di creare client alternativi, tool di analytics e integrazioni. Piattaforme collaborative come GitHub utilizzano API REST per permettere l'automazione di workflow di sviluppo, integrazione con CI/CD, e gestione programmatica di repository. Servizi e-commerce come Stripe, PayPal e Amazon forniscono API REST per processare pagamenti, gestire cataloghi prodotti e tracciare spedizioni.\cite{browserstack-rest}

\subsubsection{Open Banking e Settore Finanziario}
Il settore bancario ha abbracciato REST come tecnologia chiave per l'Open Banking, un paradigma regolamentato che richiede alle banche di esporre dati e funzionalità a terze parti autorizzate. API REST standardizzate permettono aggregazione di conti, iniziazione di pagamenti e verifica dell'identità. La natura stateless di REST e la possibilità di implementare robusti meccanismi di sicurezza lo rendono ideale per questi scenari dove sicurezza, auditing e compliance sono critici.\cite{cfte-openbanking}

\subsubsection{Architetture a Microservizi}
REST rappresenta il "collante" naturale per integrare microservizi in sistemi distribuiti. In un'architettura a microservizi, ciascun servizio gestisce un dominio specifico (utenti, ordini, inventario, notifiche) ed espone le proprie funzionalità attraverso API REST. I vantaggi includono autonomia dei team, resilienza, scalabilità granulare ed eterogeneità tecnologica.\cite{xapihub-microservices}

\section{GraphQL}

\subsection{Un Linguaggio di Query per le API}

GraphQL è un linguaggio di query per API e un runtime lato server per l'esecuzione di query, sviluppato internamente da Facebook nel 2012 e rilasciato come progetto open source nel 2015. A differenza dei tradizionali approcci REST che espongono multiple endpoint con strutture di dati predefinite, GraphQL introduce un paradigma radicalmente diverso: permette ai client di specificare esattamente quali dati necessitano attraverso un'interfaccia unificata.\cite{graphql-org}

\subsubsection{Il Cuore di GraphQL: Schema e Type System}
Al centro di GraphQL si trova lo schema, che rappresenta il contratto tra client e server e definisce la forma dei dati disponibili. Lo schema viene scritto utilizzando il Schema Definition Language (SDL), un linguaggio leggibile e dichiarativo che descrive i tipi di dati e le relazioni tra essi.\cite{wpgraphql-intro}

Un esempio di schema GraphQL semplice:

\begin{verbatim}
type User {
  id: ID!
  name: String!
  email: String!
  posts: [Post!]!
}

type Post {
  id: ID!
  title: String!
  content: String
  author: User!
}

type Query {
  user(id: ID!): User
  posts: [Post!]!
}
\end{verbatim}

In questo schema, il punto esclamativo (!) indica che un campo è non-nullable, garantendo che quel campo restituirà sempre un valore. Le parentesi quadre indicano liste di elementi. Questa tipizzazione forte è uno dei pilastri fondamentali di GraphQL.\cite{github-graphql}

\subsubsection{Query, Mutations e Subscriptions}
GraphQL definisce tre tipi principali di operazioni:\cite{redhat-graphql}

\begin{itemize}
\item \textbf{Query:} Operazioni di lettura, equivalenti alle richieste GET in REST. Permettono di recuperare dati dal server.
\item \textbf{Mutations:} Operazioni di scrittura (creazione, aggiornamento, eliminazione), equivalenti a POST, PUT, DELETE in REST.
\item \textbf{Subscriptions:} Operazioni per ricevere aggiornamenti in tempo reale dal server quando si verificano eventi specifici.
\end{itemize}

Un esempio di query GraphQL mostra come il client possa richiedere esattamente i campi necessari:

\begin{verbatim}
query {
  user(id: "123") {
    name
    email
    posts {
      title
      content
    }
  }
}
\end{verbatim}

La risposta avrà esattamente la stessa struttura della query, restituendo solo i dati richiesti. Questa corrispondenza diretta tra la forma della query e la forma della risposta rende GraphQL altamente intuitivo e prevedibile.\cite{apollographql-basics}

\subsection{Punti di Forza: Flessibilità delle Query, Efficienza dei Dati, Tipizzazione Forte}

\subsubsection{Risoluzione dei Problemi di Over-Fetching e Under-Fetching}
Il principale vantaggio di GraphQL è la sua capacità di risolvere i problemi endemici di over-fetching e under-fetching che affliggono le API REST. Con REST, un endpoint tipicamente restituisce una struttura di dati fissa, che può contenere più informazioni di quelle necessarie (over-fetching) o richiedere multiple chiamate per ottenere tutti i dati necessari (under-fetching).\cite{reddit-graphql-benefits}

GraphQL elimina questi problemi permettendo al client di specificare precisamente quali campi desidera. Un'applicazione mobile con banda limitata può richiedere solo i campi essenziali, mentre un'applicazione desktop con maggiori risorse può richiedere dati più dettagliati, tutto utilizzando lo stesso endpoint GraphQL.\cite{aws-graphql-diff}

\subsubsection{Single Endpoint e Riduzione del Traffico di Rete}
A differenza di REST che tipicamente richiede multiple endpoint per risorse diverse, GraphQL opera attraverso un singolo endpoint. Questo approccio offre numerosi vantaggi pratici:\cite{youtube-graphql}

\begin{itemize}
\item \textbf{Riduzione delle Richieste di Rete:} Invece di fare multiple chiamate HTTP sequenziali per aggregare dati da diverse risorse, un client può fare una singola richiesta GraphQL che recupera tutti i dati necessari.
\item \textbf{Payload Ridotti:} Richiedendo solo i campi necessari, GraphQL riduce significativamente la quantità di dati trasferiti sulla rete.
\item \textbf{Latenza Ridotta:} Meno round-trip al server significa tempi di risposta più rapidi e un'esperienza utente più fluida.
\end{itemize}

\subsubsection{Tipizzazione Forte e Validazione}
GraphQL è fortemente tipizzato. Ogni campo nello schema ha un tipo specifico, e GraphQL valida che tutte le query rispettino questo sistema di tipi prima dell'esecuzione. Questo offre numerosi benefici:\cite{learning-atheros}

\begin{itemize}
\item \textbf{Validazione Anticipata:} Gli errori vengono catturati durante lo sviluppo, prima che il codice raggiunga produzione.
\item \textbf{Autocompletamento e Tooling:} Gli IDE possono offrire autocompletamento intelligente e rilevamento errori in tempo reale.
\item \textbf{Documentazione Auto-Generata:} Il sistema di tipi funge da documentazione vivente.
\item \textbf{Contratti Espliciti:} Lo schema definisce chiaramente cosa è possibile richiedere e quale sarà la forma della risposta.
\end{itemize}

\subsection{Debolezze: Complessità Lato Server, Gestione della Cache}

\subsubsection{Complessità Implementativa Lato Server}
L'implementazione di un server GraphQL è significativamente più complessa rispetto a un'API REST equivalente. Questa complessità si manifesta in diverse aree:\cite{reddit-graphql-hate}

\begin{itemize}
\item \textbf{Progettazione dello Schema:} Creare uno schema GraphQL ben progettato richiede un'attenta pianificazione.
\item \textbf{Implementazione dei Resolver:} Ogni campo nello schema necessita di un resolver, e l'orchestrazione di questi resolver per query complesse può diventare intricata.
\item \textbf{Curva di Apprendimento:} Il paradigma GraphQL richiede un cambio di mentalità rispetto a REST.
\end{itemize}

\subsubsection{Il Problema N+1 e Ottimizzazione delle Performance}
Uno dei problemi più insidiosi in GraphQL è il problema N+1. Questo si verifica quando una query che restituisce una lista di N elementi scatena N+1 chiamate al database o ad altri servizi.\cite{dev-nplus1}

La soluzione standard al problema N+1 è l'utilizzo di DataLoader, una utility sviluppata da Facebook specificamente per GraphQL. DataLoader implementa due strategie chiave: batching (raccoglie tutte le richieste individuali e le combina in una singola query batch) e caching (memorizza i risultati durante l'esecuzione di una richiesta).\cite{wundergraph-dataloader}

\subsubsection{Complessità della Gestione della Cache}
La gestione della cache rappresenta una delle sfide più significative di GraphQL. A differenza di REST dove il caching HTTP può essere implementato facilmente usando l'URL come chiave, GraphQL presenta difficoltà intrinseche:\cite{apollographql-caching}

\begin{itemize}
\item \textbf{POST e Caching HTTP:} Per impostazione predefinita, GraphQL utilizza il metodo HTTP POST per tutte le operazioni, e le richieste POST non vengono automaticamente cachate dai meccanismi HTTP standard.
\item \textbf{Identificazione Univoca delle Query:} Anche quando due query richiedono gli stessi dati, piccole differenze nella sintassi possono rendere le query testuali diverse.
\item \textbf{Invalidazione Granulare della Cache:} Quando un dato viene modificato, è difficile determinare quali query cachate devono essere invalidate.
\end{itemize}

\subsection{Scenari di Applicazione Ideali}

\subsubsection{Applicazioni Mobile e Dispositivi con Banda Limitata}
GraphQL è particolarmente adatto per applicazioni mobile dove la banda è limitata e costosa. La capacità di richiedere esattamente i dati necessari riduce il consumo di dati e migliora la responsività. Aziende come Instagram e Facebook hanno adottato GraphQL proprio per ottimizzare l'esperienza mobile.\cite{apipark-graphql-examples}

\subsubsection{Architetture a Microservizi e GraphQL Federation}
Per organizzazioni con architetture a microservizi, GraphQL Federation offre una soluzione elegante per unificare API distribuite. Federation permette a team indipendenti di possedere e gestire porzioni dello schema GraphQL (chiamate "subgraph"), che vengono poi composte in un "supergraph" unificato tramite un gateway.\cite{dev-netflix-graphql}

Netflix rappresenta un caso di studio esemplare. Dopo aver utilizzato per anni una propria soluzione proprietaria, Netflix ha migrato le sue applicazioni iOS e Android a GraphQL Federation nel 2022. I risultati per Netflix sono stati significativi: eliminazione del collo di bottiglia del team API centrale, autonomia dei team con ownership chiara, e unificazione delle API.\cite{apollographql-netflix}

\subsubsection{Applicazioni Real-Time e Subscriptions}
Per applicazioni che richiedono aggiornamenti in tempo reale, le GraphQL Subscriptions offrono un meccanismo elegante. Le subscriptions mantengono una connessione persistente (tipicamente via WebSocket) tra client e server, permettendo al server di pushare aggiornamenti quando si verificano eventi.\cite{hasura-subscriptions}

Casi d'uso ideali includono:
\begin{itemize}
\item Chat e Messaging: Notifiche istantanee di nuovi messaggi
\item Live Dashboards: Aggiornamenti in tempo reale di metriche e KPI
\item Applicazioni Collaborative: Editor condivisi, lavagne virtuali
\item Trading e Finanza: Aggiornamenti di prezzi in tempo reale
\item IoT e Monitoring: Notifiche immediate sullo stato di dispositivi
\end{itemize}

\section{WebSocket}

\subsection{Comunicazione Full-Duplex Persistente}

WebSocket rappresenta un protocollo di comunicazione standardizzato dall'IETF (Internet Engineering Task Force) come RFC 6455 nel dicembre 2011, progettato per abilitare comunicazione bidirezionale, full-duplex e in tempo reale tra client e server su una singola connessione TCP persistente. A differenza del tradizionale modello HTTP request-response, WebSocket stabilisce un canale di comunicazione continuo che rimane aperto per l'intera durata della sessione, permettendo sia al client che al server di inviare dati indipendentemente e simultaneamente, senza necessità di nuove richieste.\cite{websocket-org}

\subsubsection{Il Meccanismo di Handshake e Upgrade}
WebSocket inizia la sua vita come una connessione HTTP standard, sfruttando un elegante meccanismo di upgrade per trasformarsi in una connessione WebSocket. Questo processo di handshake garantisce la compatibilità con l'infrastruttura web esistente, permettendo a WebSocket di operare sulle stesse porte utilizzate da HTTP (porta 80 per connessioni non criptate e porta 443 per connessioni sicure).\cite{gcore-websocket}

Il processo di handshake si svolge in fasi ben definite:\cite{metered-websocket}

\begin{enumerate}
\item \textbf{Richiesta di Upgrade dal Client:} Il client invia una richiesta HTTP GET contenente header speciali che indicano l'intenzione di upgradare la connessione a WebSocket.
\item \textbf{Risposta del Server:} Se il server supporta WebSocket e accetta l'upgrade, risponde con un codice di stato HTTP 101 Switching Protocols.
\item \textbf{Connessione Stabilita:} Dopo l'handshake di successo, la connessione HTTP è stata "upgradata" a WebSocket.
\end{enumerate}

\subsubsection{Struttura dei Frame WebSocket}
Dopo l'handshake, i dati vengono scambiati sotto forma di frame WebSocket. Un frame è l'unità fondamentale di comunicazione WebSocket e consiste in un header compatto seguito dai dati del payload.\cite{studyraid-frames}

La struttura di un frame include:
\begin{itemize}
\item \textbf{FIN bit (1 bit):} Indica se questo è il frame finale di un messaggio.
\item \textbf{Opcode (4 bit):} Identifica il tipo di frame (testo, binario, close, ping, pong).
\item \textbf{Mask bit (1 bit):} Indica se il payload è mascherato. Per sicurezza, tutti i frame inviati dal client al server devono essere mascherati.
\item \textbf{Payload length:} Indica la lunghezza del payload.
\item \textbf{Payload data:} I dati effettivi del messaggio.
\end{itemize}

\subsubsection{Tipi di Frame e Messaggi}
WebSocket supporta due tipi principali di messaggi di dati:\cite{hpbn-websocket}

\begin{itemize}
\item \textbf{Frame di Testo (0x01):} Contengono dati codificati in UTF-8. Il protocollo WebSocket include validazione UTF-8.
\item \textbf{Frame Binari (0x02):} Contengono dati binari raw senza interpretazione. L'uso di frame binari può essere 2x più veloce rispetto ai frame di testo poiché elimina la necessità di encoding/decoding e validazione UTF-8.
\end{itemize}

Inoltre, WebSocket definisce frame di controllo per gestire la connessione: Ping/Pong (meccanismo di keepalive) e Close (per chiudere gracefully la connessione).\cite{django-websocket-heartbeat}

\subsubsection{Persistenza e Full-Duplex}
La caratteristica distintiva di WebSocket è la sua natura persistente e full-duplex.\cite{ably-websocket-pros}

Persistente significa che, una volta stabilita, la connessione rimane aperta finché una delle due parti decide attivamente di chiuderla. Questo elimina l'overhead di stabilire ripetutamente connessioni, riduce drasticamente la latenza e rende possibile la comunicazione in tempo reale.\cite{cdebyte-websocket-http}

Full-duplex significa che i dati possono fluire simultaneamente in entrambe le direzioni. Il client può inviare messaggi al server mentre contemporaneamente riceve messaggi dal server, senza dover attendere risposte. Questo è fondamentalmente diverso dal modello half-duplex di HTTP.\cite{ably-websocket-fullduplex}

\subsection{Punti di Forza: Bassa Latenza, Comunicazione Real-Time, Efficienza}

\subsubsection{Bassa Latenza e Performance Real-Time}
WebSocket offre latenza drasticamente ridotta rispetto alle alternative basate su HTTP. Questa riduzione di latenza proviene da diversi fattori:\cite{verpex-websocket}

\begin{itemize}
\item \textbf{Eliminazione dell'Overhead di Connessione:} Con HTTP, ogni richiesta richiede un three-way handshake TCP, negoziazione TLS, e invio di header HTTP completi. WebSocket esegue questo processo una sola volta durante l'handshake iniziale.
\item \textbf{Messaggi Immediati:} Poiché la connessione è sempre aperta, non c'è ritardo di stabilimento connessione.
\item \textbf{Eliminazione del Polling:} Tecniche HTTP tradizionali come il polling o long-polling introducono latenza intrinseca. WebSocket elimina completamente questi pattern inefficienti.
\end{itemize}

Studi hanno dimostrato che WebSocket può ridurre la latenza fino al 50\% rispetto a long-polling in applicazioni real-time come chat. In applicazioni di trading finanziario, WebSocket può fornire aggiornamenti con latenza inferiore a 50ms.\cite{ijnrd-websocket}

\subsubsection{Efficienza di Banda e Riduzione dell'Overhead}
WebSocket è significativamente più efficiente in termini di utilizzo della banda rispetto a HTTP.\cite{ably-websocket-efficiency}

Dopo l'handshake iniziale, i messaggi WebSocket hanno un overhead minimo. Un frame WebSocket può avere un header di soli 2-14 byte, a seconda della dimensione del payload. In contrasto, ogni richiesta HTTP include header che tipicamente ammontano a centinaia di byte.\cite{maybe-websocket}

Per applicazioni che scambiano messaggi frequentemente, questa differenza diventa drammatica. Il risparmio di banda si traduce in riduzione dei costi di infrastruttura, migliore esperienza mobile e scalabilità migliorata.\cite{sendbird-websocket-efficiency}

\subsubsection{Comunicazione Event-Driven e Bidirezionale}
WebSocket implementa un modello event-driven di comunicazione. I messaggi vengono inviati solo quando c'è effettivamente qualcosa da comunicare, non su base periodica come nel polling.\cite{dev-websocket-realtime}

La natura bidirezionale di WebSocket permette scenari di comunicazione complessi:\cite{voximplant-websocket}

\begin{itemize}
\item \textbf{Server Push:} Il server può inviare dati al client proattivamente, senza attendere una richiesta.
\item \textbf{Comunicazione Simultanea:} Client e server possono inviare messaggi simultaneamente, abilitando pattern di comunicazione necessari in applicazioni collaborative e multiplayer.
\end{itemize}

\subsubsection{Supporto per Dati Binari}
WebSocket supporta nativamente la trasmissione di dati binari oltre a testi. Questo è particolarmente vantaggioso per:\cite{oracle-websocket-binary}

\begin{itemize}
\item Streaming Media: Video, audio e immagini senza encoding Base64
\item Applicazioni Gaming: Stati di gioco e assets in formato binario compatto
\item Dati IoT: Sensori che inviano letture in formato binario efficiente
\end{itemize}

\subsection{Debolezze: Gestione dello Stato, Complessità di Scaling}

\subsubsection{Natura Stateful e Complessità di Gestione dello Stato}
A differenza di HTTP che è inherentemente stateless, WebSocket è stateful. Ogni connessione WebSocket mantiene stato per tutta la sua durata, includendo informazioni sulla sessione, contesto utente, e buffer di messaggi.\cite{nooptoday-websocket-scaling}

Questa natura stateful introduce diverse complicazioni:
\begin{itemize}
\item \textbf{Affinità di Connessione:} Una volta che un client stabilisce una connessione WebSocket con un server specifico, quella connessione è legata a quel server.
\item \textbf{Impossibilità di Memorizzare Solo i Dati:} Le connessioni WebSocket sono connessioni di rete effettive che esistono nella memoria del server. Non è possibile "salvare" una connessione in Redis e riprenderla da un altro server.
\item \textbf{Complessità nella Sincronizzazione dello Stato:} Se l'applicazione mantiene stato addizionale, questo deve essere sincronizzato tra server.
\end{itemize}

\subsubsection{Sfide di Scalabilità Orizzontale}
La scalabilità orizzontale è una strategia fondamentale per applicazioni web moderne. WebSocket rende questo processo significativamente più complesso.\cite{dev-websocket-loadbalancing}

\paragraph{Il Problema del Load Balancing}
Load balancer tradizionali distribuiscono richieste HTTP tra server in modo round-robin. Con WebSocket, questo non funziona. Una volta stabilita una connessione, tutte le comunicazioni future devono andare allo stesso server. Questo richiede sticky sessions (o session affinity).\cite{ably-websocket-loadbalancing}

Sticky sessions presentano le proprie sfide:
\begin{itemize}
\item \textbf{Distribuzione Disomogenea del Carico:} Alcuni server possono accumulare molte connessioni mentre altri rimangono relativamente liberi.
\item \textbf{Difficoltà di Failover:} Se un server fallisce, tutte le connessioni vengono perse.
\item \textbf{Complessità nel Scaling Dinamico:} Aggiungere o rimuovere server diventa complicato.
\end{itemize}

\paragraph{Necessità di Message Broker per Comunicazione Inter-Server}
Quando un messaggio deve essere inviato a un utente la cui connessione è su un server diverso, i server devono comunicare tra loro. Questo richiede un message broker come Redis Pub/Sub, RabbitMQ, o Kafka.\cite{sap-websocket-scaling}

Esempio: In un'applicazione di chat, se l'utente A (connesso al Server 1) invia un messaggio all'utente B (connesso al Server 2):
\begin{enumerate}
\item Server 1 riceve il messaggio dall'utente A
\item Server 1 pubblica il messaggio al message broker
\item Server 2 è sottoscritto al broker e riceve il messaggio
\item Server 2 invia il messaggio all'utente B tramite la sua connessione WebSocket
\end{enumerate}

Questo aggiunge latenza, complessità architetturale e un ulteriore punto di fallimento.

\subsubsection{Gestione delle Risorse e Limiti di Connessione}
Ogni connessione WebSocket consuma risorse sul server:\cite{dev-websocket-resources}

\begin{itemize}
\item \textbf{File Descriptor:} Ogni connessione occupa un file descriptor. I sistemi operativi hanno limiti sul numero di file descriptor aperti.
\item \textbf{Memoria:} Buffer di invio/ricezione, stato della connessione e oggetti applicativi associati consumano memoria.
\item \textbf{CPU:} Processare messaggi, validare frame e gestire eventi per migliaia di connessioni richiede CPU.
\end{itemize}

\subsubsection{Complessità di Heartbeat e Gestione della Connessione}
Le connessioni WebSocket possono "morire silenziosamente" a causa di problemi di rete, timeout di proxy/firewall intermedi, o crash di client, senza che il server venga notificato.\cite{github-websocket-heartbeat}

Per rilevare connessioni morte, è necessario implementare un meccanismo di heartbeat (ping/pong). Tipicamente:\cite{websockets-readthedocs-keepalive}

\begin{enumerate}
\item Il server invia periodicamente frame di PING al client (ogni 20-60 secondi)
\item Il client risponde con frame di PONG
\item Se il server non riceve PONG entro un timeout, considera la connessione morta e la chiude
\end{enumerate}

Implementare correttamente heartbeat, gestire timeout e implementare logica di riconnessione automatica aggiunge complessità sia lato client che lato server.\cite{reddit-websocket-heartbeat}

\subsection{Applicazioni Real-Time e Interattive}

WebSocket eccelle in scenari che richiedono comunicazione real-time, bassa latenza e interazioni bidirezionali.

\subsubsection{Applicazioni di Chat e Messaging}
Le applicazioni di chat rappresentano uno dei casi d'uso più comuni e naturali per WebSocket. WebSocket permette:\cite{dev-websocket-chat}

\begin{itemize}
\item Consegna Istantanea dei Messaggi: Non appena un utente invia un messaggio, viene immediatamente consegnato ai destinatari senza polling o ritardi.
\item Indicatori di Digitazione: Il client può inviare eventi "typing" al server che li inoltra ad altri partecipanti in tempo reale.
\item Stato di Presenza: Aggiornamenti immediati quando utenti vanno online/offline.
\item Ricevute di Lettura: Notifiche istantanee quando i messaggi sono stati letti.
\end{itemize}

Piattaforme come Slack, WhatsApp Web, Facebook Messenger e Discord utilizzano WebSocket per fornire esperienze di messaging fluide.\cite{algomaster-websocket-chat}

\subsubsection{Gaming Online Multiplayer}
Gaming real-time richiede sincronizzazione istantanea dello stato di gioco tra tutti i giocatori. WebSocket offre:\cite{pusher-websocket-gaming}

\begin{itemize}
\item Bassa Latenza: Critica per gameplay responsivo. Ritardi di anche 100ms possono rendere un gioco ingiocabile.
\item Aggiornamenti Frequenti: Stati di gioco (posizioni giocatori, salute, punteggi) devono essere trasmessi molte volte al secondo.
\item Sincronizzazione Bidirezionale: Ogni giocatore invia azioni al server che le valida e le propaga a tutti gli altri giocatori.
\end{itemize}

Esempi notevoli includono BrowserQuest di Mozilla, Agar.io e giochi .io simili che utilizzano WebSocket per sincronizzare migliaia di giocatori simultanei.\cite{stackoverflow-websocket-gaming}

\subsubsection{Trading Finanziario e Dati di Mercato Real-Time}
Il settore finanziario richiede aggiornamenti di dati con latenza ultra-bassa. WebSocket è lo standard per:\cite{kite-websocket}

\begin{itemize}
\item Streaming di Prezzi di Azioni: Quotazioni in tempo reale che cambiano millisecondo per millisecondo.
\item Dati di Market Depth: Aggiornamenti continui dei livelli di bid/offer.
\item Esecuzione Ordini: Conferme immediate di trade eseguiti.
\item Alert e Notifiche: Notifiche immediate di eventi di mercato rilevanti.
\end{itemize}

Piattaforme come Bloomberg Terminal, Interactive Brokers, Binance e Coinbase utilizzano WebSocket per fornire dati real-time.\cite{videosdk-websocket-trading}

\subsubsection{Applicazioni Collaborative}
Strumenti di collaborazione dove multipli utenti lavorano simultaneamente sullo stesso documento o progetto beneficiano enormemente di WebSocket:\cite{linkedin-websocket-usecases}

\begin{itemize}
\item Editor di Documenti Collaborativi: Google Docs, Notion utilizzano WebSocket per sincronizzare modifiche in tempo reale tra utenti.
\item Lavagne Virtuali: Miro, Mural permettono a team di disegnare e brainstormare insieme in tempo reale.
\item Code Editor Condivisi: Visual Studio Code Live Share, Replit consentono pair programming con editing simultaneo.
\end{itemize}

Tecniche come Operational Transformation (OT) o Conflict-free Replicated Data Types (CRDTs) vengono utilizzate insieme a WebSocket per gestire modifiche concorrenti senza conflitti.\cite{videosdk-websocket-collaboration}

\subsubsection{Streaming di Dati e Broadcasting}
WebSocket è ideale per broadcasting di dati a molti client simultaneamente:\cite{ably-websocket-streaming}

\begin{itemize}
\item Live Sports Updates: Punteggi, statistiche e eventi di gioco trasmessi istantaneamente a milioni di fan.
\item Notizie e Alert: Breaking news, alert meteo, notifiche di emergenza.
\item Dashboard Live: Monitoring di metriche di business, KPI, analytics in tempo reale.
\item Live Polling e Quiz: Applicazioni dove utenti votano e vedono risultati aggiornarsi in tempo reale.
\end{itemize}

\subsubsection{Dashboard Live e Monitoraggio}
WebSocket permette di costruire dashboard di monitoraggio che si aggiornano automaticamente senza necessità di refresh. Questo è particolarmente utile per:\cite{dotcom-monitor-websocket}

\begin{itemize}
\item Monitoraggio Infrastrutture IT: Dashboard che mostrano stato di server, latenza di rete, utilizzo risorse CPU/memoria in tempo reale. Strumenti come Prometheus e Grafana utilizzano WebSocket per visualizzare metriche live.
\item Business Intelligence: KPI aziendali, vendite, conversioni e metriche di performance aggiornate istantaneamente per decision maker.
\item DevOps e Logging: Stream di log applicativi, errori e tracce di esecuzione visualizzati in tempo reale per debugging e troubleshooting.
\item Network Operations Center (NOC): Visualizzazione dello stato di reti, dispositivi e servizi con alert immediati su anomalie.
\end{itemize}

\subsubsection{IoT e Telemetria}
Nel mondo dell'Internet of Things (IoT), WebSocket è diventato un protocollo chiave per la comunicazione tra dispositivi e server cloud. Le applicazioni spaziano in diversi settori:\cite{appmaster-websocket-iot}

\begin{itemize}
\item Smart Home: Dispositivi domestici intelligenti (termostati, luci, serrature, sensori) comunicano con hub centrali e app mobili via WebSocket, permettendo controllo remoto istantaneo e notifiche di eventi.
\item Industrial Automation: Fabbriche e impianti industriali utilizzano WebSocket per trasmettere dati da sensori di produzione, controllare macchinari remotamente e monitorare parametri critici in tempo reale.
\item Healthcare Monitoring: Dispositivi medici indossabili (smartwatch, sensori biometrici) trasmettono dati vitali a piattaforme cloud via WebSocket per monitoraggio continuo di pazienti.
\item Connected Vehicles: Sistemi telematici automotive utilizzano WebSocket per trasmettere diagnostica veicolo, posizione GPS, stato batteria e ricevere comandi remoti.
\item Environmental Monitoring: Sensori ambientali trasmettono dati in tempo reale per analisi e alert.
\end{itemize}

Grafana ha sviluppato un plugin WebSocket specifico per IoT che permette di visualizzare dati da dispositivi in tempo reale, aggiornando automaticamente i pannelli senza polling.\cite{grafana-websocket-iot}

\subsubsection{Notifiche Push e Alert Real-Time}
WebSocket è ideale per implementare sistemi di notifiche push che devono raggiungere gli utenti istantaneamente:\cite{codefinity-websocket-notifications}

\begin{itemize}
\item Notifiche Applicative: Alert di nuovi messaggi, menzioni social, aggiornamenti di status, completamento di task lunghi.
\item E-commerce: Notifiche di ordini confermati, spedizioni, aggiornamenti di tracking, disponibilità prodotti.
\item Emergency Alerts: Sistemi di allerta per emergenze (meteo estremo, evacuazioni, incidenti) che devono raggiungere utenti immediatamente.
\item Notifiche Amministrative: Dashboard admin che ricevono notifiche istantanee di nuovi ordini, registrazioni utenti o eventi critici senza dover ricaricare la pagina.
\end{itemize}

Implementazioni tipiche utilizzano Node.js con la libreria ws per gestire connessioni WebSocket, Redis come message broker per coordinare notifiche tra server multipli, e meccanismi di autenticazione per garantire che solo utenti autorizzati ricevano notifiche specifiche.\cite{rust-users-websocket}

\subsubsection{Social Media e Feed Live}
Piattaforme social media utilizzano WebSocket per fornire esperienze altamente interattive:\cite{zscaler-websocket}

\begin{itemize}
\item Feed Updates: Nuovi post, foto, video appaiono nel feed senza refresh.
\item Likes e Reactions: Contatori di like aggiornati in tempo reale quando altri utenti interagiscono.
\item Live Comments: Commenti su post o video live che appaiono istantaneamente.
\item Presenza Utenti: Indicatori di chi è online/offline, stato "sta scrivendo".
\item Live Streaming: Piattaforme come Twitch, YouTube Live utilizzano WebSocket per gestire chat live, donazioni e metadata dello stream.
\end{itemize}

\subsubsection{Location Tracking e Logistica}
Applicazioni di tracking e logistica beneficiano enormemente di WebSocket:\cite{videosdk-websocket-location}

\begin{itemize}
\item Fleet Management: Tracking di veicoli commerciali, ottimizzazione route, monitoring consumi carburante.
\item Ride-Sharing: Uber, Lyft utilizzano WebSocket per aggiornare posizione driver in tempo reale sulla mappa utente.
\item Delivery Tracking: Visualizzazione della posizione del corriere in tempo reale per ordini food delivery o pacchi.
\item Asset Tracking: Monitoraggio di container, attrezzature, inventory in movimento.
\end{itemize}

\subsection{Considerazioni Finali}

\subsubsection{Tooling e Debugging}
Il debugging di applicazioni WebSocket presenta sfide uniche rispetto a HTTP. L'ecosistema di strumenti è in continua evoluzione:\cite{dotcom-monitor-tools}

\begin{itemize}
\item Browser Developer Tools: Chrome, Firefox includono supporto per ispezionare connessioni WebSocket.
\item Wireshark: Per analisi packet-level dettagliata.
\item Dotcom-Monitor: Piattaforma di monitoring sintetico che emula connessioni WebSocket reali.
\item Artillery e k6: Framework di load testing che supportano WebSocket.
\item Postman: Supporta testing di WebSocket con interfaccia grafica.
\end{itemize}

Monitoring in produzione dovrebbe includere metriche chiave come Connection Success Rate, Handshake Latency, Message Throughput, Round-Trip Latency, Reconnection Frequency, Active Connections Count e Backpressure.\cite{dotcom-monitor-metrics}

\subsubsection{Conclusione WebSocket}
WebSocket rappresenta un pilastro fondamentale dell'architettura web moderna per applicazioni real-time. La sua capacità di fornire comunicazione bidirezionale persistente con latenza minimale lo rende insostituibile in scenari come chat, gaming, trading finanziario, IoT e collaborative tools. Tuttavia, questa potenza viene con costi di complessità: gestione dello stato, scaling orizzontale complesso e necessità di infrastructure dedicata per message brokering e load balancing.

Le organizzazioni che implementano WebSocket devono investire in architetture robuste che gestiscano heartbeat, riconnessione automatica, message queuing e monitoring approfondito. I benefici in termini di user experience e performance real-time giustificano ampiamente questo investimento per le applicazioni giuste.

Con l'evoluzione continua del web verso esperienze sempre più interattive e real-time, WebSocket continuerà a giocare un ruolo centrale, complementando REST e GraphQL per costruire l'ecosistema di comunicazione completo necessario per applicazioni moderne.\cite{ably-websocket-conclusion}

\section{MCP (Model Context Protocol)}

\subsection{Cenni sul protocollo e il suo ambito}

Il Model Context Protocol (MCP) nasce nel 2024 da una collaborazione tra Anthropic e vari enti di standardizzazione, con l'obiettivo di definire un formato unificato per l'integrazione tra modelli di intelligenza artificiale e servizi esterni. MCP si propone come "linguaggio ponte" in grado di gestire in modo coerente e persistente il contesto di esecuzione, le funzioni disponibili ("tool"), le risorse dati e i flussi di notifiche, superando i limiti dei tradizionali protocolli REST e GraphQL in scenari agentici.\cite{anthropic-mcp}

L'architettura MCP prevede due componenti principali:

\begin{itemize}
\item \textbf{Client MCP}, integrato in agenti AI o applicazioni host, responsabile di orchestrare il contesto, formulare richieste e processare risposte "strumentali";
\item \textbf{Server MCP}, che espone endpoint JSON-RPC 2.0 su trasporti come HTTP/1.1, HTTP/2 (con Server-Sent Events per lo streaming), WebSocket o stdio, offrendo metodi per interrogare strumenti, invocare funzioni e ricevere notifiche di eventi.
\end{itemize}

Grazie a un meccanismo di "handshake contestuale", MCP stabilisce una sessione persistente entro cui il client e il server condividono metadati, autorizzazioni, token di autenticazione e uno stato di dialogo che evolve durante l'interazione.\cite{milvus-mcp}

\subsection{Punti di forza: gestione del contesto ed efficienza per agenti intelligenti}

\subsubsection{Gestione contestuale nativa}
MCP introduce una sessione contestuale persistente, eliminando la necessità di includere interamente lo stato in ogni singola richiesta HTTP. Una volta stabilita, la sessione memorizza:

\begin{itemize}
\item Cronologia delle chiamate e delle risposte
\item Autorizzazioni granulari per ciascun tool
\item Cache temporanee di dati frequentemente riutilizzati
\item Flag di avanzamento di task complessi
\end{itemize}

Questa architettura riduce la ridondanza nei payload e accelera la risposta degli agenti AI, che possono fare riferimento al contesto condiviso per estrarre variabili, risultati intermedi e configurazioni.\cite{codica-mcp}

\subsubsection{Efficienza nell'invocazione di funzioni}
MCP formalizza il pattern di "function calling": i server espongono metodi descritti con interfacce dichiarative (nomi, parametri, tipi di ritorno, permessi), che il client può scoprire dinamicamente. I metodi si suddividono in:\cite{philschmid-mcp}

\begin{itemize}
\item \textbf{Tools:} funzioni con effetto (es. sendEmail, createTicket);
\item \textbf{Resources:} endpoint read-only (es. queryOrders, fetchDocument);
\item \textbf{Streams:} canali di eventi push (es. notifiche di completamento task).
\end{itemize}

A differenza delle invocazioni REST/GraphQL, che richiedono endpoint differenti e sintassi variabile, MCP descrive tutto in un registro centralizzato, permettendo agenti generici di esplorare, filtrare e invocare metodi senza codice specifico per ogni tool.\cite{auth0-mcp}

\subsection{Limiti e confronto con approcci più general-purpose}

\subsubsection{Complessità architetturale e maturità}
L'adozione di MCP introduce complessità rispetto alla semplicità stateless di REST e GraphQL. Gestire sessioni, sincronizzare cache e orchestrare notifiche push richiede un'infrastruttura più articolata. Poiché MCP è una tecnologia recente (2024-2025), l'ecosistema di librerie client/server, strumenti di debugging e guide best-practice non è ancora paragonabile a quello maturo di HTTP/REST e GraphQL.\cite{bcg-mcp}

\subsubsection{Ambito di utilizzo specialistico}
MCP eccelle nei casi di automazione AI-driven e orchestrazione agentica, ma per scenari CRUD tradizionali, query dati monolitiche o integrazioni semplici, REST e GraphQL rimangono più immediati ed efficienti. GraphQL offre flessibilità di selezione dei campi con un singolo endpoint e una forte tipizzazione, mentre MCP aggiunge overhead di sessione senza benefici sostanziali in scenari di singola query.\cite{openreplay-mcp}

\subsection{Scenari di utilizzo emergenti}

\subsubsection{Orchestrazione di agenti multi-tool}
In ambienti dove agenti AI devono coordinare più strumenti eterogenei (browser automation, database, servizi cloud, plugin custom), MCP permette di registrare ogni tool come server MCP e fornisce agli agenti un unico canale per elencare, interrogare e invocare ciascuno di essi senza scrivere integrazioni dedicate.\cite{philschmid-mcp-agents}

\subsubsection{Assistenti di sviluppo e IDE AI-powered}
Editor come GitHub Copilot, Cursor e Kodecor utilizzano MCP per integrare servizi esterni (CI/CD pipeline, code search, documentazione API) direttamente nel contesto di editing, consentendo a un agente di generare codice, eseguire test e correggere bug in un unico flusso persistente.\cite{modelcontextprotocol}

\subsubsection{Business automation e workflow}
Soluzioni di Robotic Process Automation (RPA) e hyperautomation possono impiegare agenti MCP-based per orchestrare processi end-to-end (estrazione dati, compilazione form, invio report), riducendo la latenza tra task e migliorando affidabilità e tracciabilità delle operazioni.\cite{bcg-automation}

\subsubsection{Digital personal assistants evoluti}
Assistenti come Claude Assistant e nuovi sviluppi di Siri e Google Assistant possono integrare calendari, email, CRM, servizi domestici e PIM tramite MCP, mantenendo contesto tra sessioni e gestendo in modo sicuro le autorizzazioni per ciascun servizio.\cite{wikipedia-mcp}

Con una crescita impressionante di implementazioni e casi d'uso dal lancio nel 2024, MCP si sta affermando come il protocollo di riferimento per l'integrazione contestuale e persistente tra agenti AI e tool esterni, aprendo nuove prospettive per l'automazione intelligente e la cooperazione tra sistemi eterogenei.\cite{codica-mcp-conclusion}

\section{Analisi Comparativa}

\subsection{Matrice di Confronto}

La seguente tabella riassume le caratteristiche principali di REST, GraphQL, WebSocket e MCP, mettendo a confronto quattro dimensioni chiave: performance, flessibilità, complessità e scalabilità.

\begin{table}[h]
\centering
\begin{tabular}{|l|p{3cm}|p{3cm}|p{2.5cm}|p{2.5cm}|}
\hline
\textbf{Tecnologia} & \textbf{Performance} & \textbf{Flessibilità} & \textbf{Complessità} & \textbf{Scalabilità} \\
\hline
REST & Elevata per operazioni CRUD semplici, grazie a caching HTTP nativo. Latenza ~50-100 ms & Limitata dalla struttura fissa degli endpoint; over-/under-fetching comuni & Bassa: modello request-response, stateless & Ottima: statelessness e caching facilitano scaling orizzontale \\
\hline
GraphQL & Ottima per ridurre round-trip: single endpoint, payload minimali; overhead ~5-10 ms/query & Molto alta: query custom, navigazione grafo dati, introspection & Media: design schema, resolver, DataLoader necessari & Buona: single endpoint semplifica routing \\
\hline
WebSocket & Eccellente per real-time: latenza < 20 ms dopo handshake, overhead minimo (2-6 byte) & Alta per scenari real-time; limitata per query dati strutturati & Media: protocollo stateful con heartbeat e riconnessione & Media-Bassa: scaling complesso con sticky sessions \\
\hline
MCP & Buona per orchestrazione agentica: sessione persistente riduce payload ripetitivi & Molto alta: discovery dinamico di tool, session context-aware & Alta: gestione sessioni, cache contestuali & Buona: session-aware ma richiede componenti di coordinamento \\
\hline
\end{tabular}
\caption{Matrice comparativa dei protocolli di comunicazione}
\end{table}

\subsection{Discussione: Quando e perché scegliere una tecnologia}

\subsubsection{REST}
REST rimane la scelta più appropriata per applicazioni con requisiti CRUD standard, dove la maggior parte delle operazioni si traduce in letture e scritture di risorse discrete. Grazie al caching HTTP e alla statelessness, REST eccelle in scenari dove il traffico dei dati è ripetitivo e i payload non cambiano frequentemente. Organizzazioni con team distribuiti e infrastrutture consolidate (microservizi, API gateway) troveranno in REST un paradigma semplice, ben documentato e facilmente integrabile con tecnologie legacy.

\subsubsection{GraphQL}
GraphQL è ideale quando il client richiede flessibilità dei dati e deve minimizzare gli overhead di rete dovuti a multiple chiamate. È perfetto per applicazioni mobile e SPA che devono recuperare strutture dati complesse in modo efficiente, evitando over-fetching e under-fetching. La tipizzazione forte e l'introspection migliorano l'esperienza dello sviluppatore, mentre le subscriptions consentono scenari real-time di base. Tuttavia, richiede competenze nel design dello schema e ottimizzazioni (DataLoader, caching avanzato).

\subsubsection{WebSocket}
WebSocket è la tecnologia di riferimento per comunicazione real-time tra client e server, con latenza ultra-bassa e supporto nativo a messaggi bidirezionali e dati binari. È perfetto per applicazioni di chat, gaming multiplayer, trading finanziario e dashboard live. Tuttavia, la natura stateful introduce complessità di scaling e gestione delle connessioni: richiede sticky sessions, broker di messaggi e strategia di heartbeat/reconnect.

\subsubsection{MCP}
MCP rappresenta uno standard emergente specifico per agenti AI e workflow contestuali, dove la sessione persistente e la gestione del contesto nativa sono indispensabili. È consigliato quando si costruiscono assistenti intelligenti, IDE AI-powered o soluzioni di business automation che devono orchestrare dinamicamente tool eterogenei senza reintegrazioni ad hoc. Non è però la scelta migliore per semplici API CRUD o per scenari in cui lo stato non è un fattore critico, dato il sovraccarico infrastrutturale e la curva di apprendimento elevata.

\subsection{Conclusione}

In sintesi, la scelta tra REST, GraphQL, WebSocket e MCP dipende dai requisiti di interazione, complessità e contesto applicativo. Per operazioni di base e integrazioni tradizionali, REST offre efficienza e semplicità. Per applicazioni dai dati complessi e esigenze di query flessibili, GraphQL è preferibile. Per scenari real-time e bidirezionali, WebSocket è imbattibile. Infine, per agenti intelligenti e orchestrazioni contestuali, MCP emerge come il protocollo più completo e avanzato, sebbene richieda un investimento maggiore in infrastruttura e competenze.

\begin{thebibliography}{99}

\bibitem{fielding2000}
Roy T. Fielding, \emph{Architectural Styles and the Design of Network-based Software Architectures}, Doctoral dissertation, University of California, Irvine, 2000.

\bibitem{restapitutorial}
REST API Tutorial, \emph{REST Architectural Constraints}, \url{https://www.restapitutorial.com}

\bibitem{restfulapi2024}
RESTful API, \emph{REST API Design Guide}, 2024.

\bibitem{wikipedia-rest}
Wikipedia, \emph{Representational State Transfer}, \url{https://en.wikipedia.org/wiki/REST}

\bibitem{caching2024}
Various authors, \emph{HTTP Caching Strategies}, 2024.

\bibitem{code-on-demand}
Various authors, \emph{Code on Demand in REST}, 2024.

\bibitem{microsoft-rest}
Microsoft Azure, \emph{REST API Design Best Practices}, 2024.

\bibitem{arbisoft-stateless}
Arbisoft, \emph{Statelessness in REST: What It Means and Why It Matters}, 2024.

\bibitem{ibm-rest}
IBM, \emph{What are REST APIs}, 2024.

\bibitem{api-statistics}
Various sources, \emph{API Market Statistics}, 2024.

\bibitem{stackoverflow-overfetching}
Stack Overflow Community, \emph{Over-fetching and Under-fetching in REST}, 2024.

\bibitem{nplus1-problem}
Various sources, \emph{The N+1 Query Problem}, 2024.

\bibitem{browserstack-rest}
BrowserStack, \emph{REST API Guide}, 2024.

\bibitem{cfte-openbanking}
Centre for Finance, Technology and Entrepreneurship, \emph{APIs in Open Banking}, 2024.

\bibitem{xapihub-microservices}
xAPIHub, \emph{REST APIs for Microservices Architecture}, 2024.

\bibitem{graphql-org}
GraphQL Foundation, \emph{Introduction to GraphQL}, \url{https://graphql.org}

\bibitem{wpgraphql-intro}
WPGraphQL, \emph{Introduction to GraphQL}, 2024.

\bibitem{github-graphql}
GitHub, \emph{About the GraphQL API}, 2024.

\bibitem{redhat-graphql}
Red Hat, \emph{What is GraphQL}, 2024.

\bibitem{apollographql-basics}
Apollo GraphQL, \emph{GraphQL Basics}, 2024.

\bibitem{reddit-graphql-benefits}
Reddit Community, \emph{Benefits of GraphQL}, 2024.

\bibitem{aws-graphql-diff}
Amazon Web Services, \emph{GraphQL vs REST}, 2024.

\bibitem{youtube-graphql}
Various creators, \emph{GraphQL Tutorial Videos}, 2024.

\bibitem{learning-atheros}
Atheros Learning, \emph{GraphQL Introspection}, 2024.

\bibitem{reddit-graphql-hate}
Reddit Community, \emph{GraphQL Criticisms}, 2024.

\bibitem{dev-nplus1}
DEV Community, \emph{N+1 Problem in GraphQL}, 2024.

\bibitem{wundergraph-dataloader}
WunderGraph, \emph{DataLoader 3.0: Breadth-First Data Loading}, 2024.

\bibitem{apollographql-caching}
Apollo GraphQL, \emph{GraphQL Caching Strategies}, 2024.

\bibitem{apipark-graphql-examples}
APIPark, \emph{GraphQL Real-World Examples}, 2024.

\bibitem{dev-netflix-graphql}
DEV Community, \emph{Why Netflix Chose GraphQL}, 2024.

\bibitem{apollographql-netflix}
Apollo GraphQL, \emph{Netflix's GraphQL Journey}, 2024.

\bibitem{hasura-subscriptions}
Hasura, \emph{GraphQL Subscriptions}, 2024.

\bibitem{websocket-org}
WebSocket.org, \emph{The WebSocket Protocol}, \url{https://websocket.org}

\bibitem{gcore-websocket}
Gcore, \emph{What is WebSocket}, 2024.

\bibitem{metered-websocket}
Metered, \emph{WebSocket Basics}, 2024.

\bibitem{studyraid-frames}
StudyRaid, \emph{Understanding WebSocket Frame Structure}, 2024.

\bibitem{hpbn-websocket}
High Performance Browser Networking, \emph{WebSocket}, 2024.

\bibitem{django-websocket-heartbeat}
Django WebSocket Redis, \emph{Heartbeats}, 2024.

\bibitem{ably-websocket-pros}
Ably, \emph{WebSocket Pros and Cons}, 2024.

\bibitem{cdebyte-websocket-http}
CDEbyte, \emph{WebSocket vs HTTP}, 2024.

\bibitem{ably-websocket-fullduplex}
Ably, \emph{Full-Duplex Communication with WebSocket}, 2024.

\bibitem{verpex-websocket}
Verpex, \emph{WebSockets for Real-Time Communication}, 2024.

\bibitem{ijnrd-websocket}
IJNRD, \emph{WebSocket Performance Study}, 2024.

\bibitem{ably-websocket-efficiency}
Ably, \emph{WebSocket Efficiency}, 2024.

\bibitem{maybe-websocket}
Maybe Works, \emph{WebSocket: What It Is, When to Use}, 2024.

\bibitem{sendbird-websocket-efficiency}
SendBird, \emph{WebSocket vs HTTP Communication Protocols}, 2024.

\bibitem{dev-websocket-realtime}
DEV Community, \emph{Real-Time with WebSockets}, 2024.

\bibitem{voximplant-websocket}
Voximplant, \emph{WebSocket for Integration}, 2024.

\bibitem{oracle-websocket-binary}
Oracle, \emph{Binary Data in WebSocket}, 2024.

\bibitem{nooptoday-websocket-scaling}
NoOpToday, \emph{Why WebSockets Are Hard to Scale}, 2024.

\bibitem{dev-websocket-loadbalancing}
DEV Community, \emph{Load Balancing WebSockets at Scale}, 2024.

\bibitem{ably-websocket-loadbalancing}
Ably, \emph{Scaling WebSockets}, 2024.

\bibitem{sap-websocket-scaling}
SAP Community, \emph{WebSocket Performance and Scalability}, 2024.

\bibitem{dev-websocket-resources}
DEV Community, \emph{WebSocket Resource Management}, 2024.

\bibitem{github-websocket-heartbeat}
GitHub, \emph{WebSocket Heartbeat Implementation}, 2024.

\bibitem{websockets-readthedocs-keepalive}
WebSockets Documentation, \emph{Keepalive and Timeouts}, 2024.

\bibitem{reddit-websocket-heartbeat}
Reddit Community, \emph{WebSocket Heartbeat Discussion}, 2024.

\bibitem{dev-websocket-chat}
DEV Community, \emph{Building Real-Time Chat with WebSockets}, 2024.

\bibitem{algomaster-websocket-chat}
AlgoMaster, \emph{Real-Time Chat System Design}, 2024.

\bibitem{pusher-websocket-gaming}
Pusher, \emph{WebSockets for Real-Time Gaming}, 2024.

\bibitem{stackoverflow-websocket-gaming}
Stack Overflow, \emph{WebSockets in Multiplayer Games}, 2024.

\bibitem{kite-websocket}
Zerodha Kite, \emph{WebSocket Documentation}, 2024.

\bibitem{videosdk-websocket-trading}
VideoSDK, \emph{WebSocket Use Cases}, 2024.

\bibitem{linkedin-websocket-usecases}
LinkedIn, \emph{Real-World Use Cases of WebSockets}, Eric Lane, 2024.

\bibitem{videosdk-websocket-collaboration}
VideoSDK, \emph{WebSocket for Collaboration}, 2024.

\bibitem{ably-websocket-streaming}
Ably, \emph{WebSocket for Data Streaming}, 2024.

\bibitem{dotcom-monitor-websocket}
Dotcom-Monitor, \emph{WebSocket Application Monitoring}, 2024.

\bibitem{appmaster-websocket-iot}
AppMaster, \emph{WebSocket for IoT Communication}, 2024.

\bibitem{grafana-websocket-iot}
Grafana Labs, \emph{Using WebSockets for Real-Time IoT Data}, 2024.

\bibitem{codefinity-websocket-notifications}
Codefinity, \emph{Real-Time Notification System with WebSockets}, 2024.

\bibitem{rust-users-websocket}
Rust Users Forum, \emph{WebSockets for Push Notifications}, 2024.

\bibitem{zscaler-websocket}
Zscaler, \emph{WebSockets: Powering Interactive Web Experiences}, 2024.

\bibitem{videosdk-websocket-location}
VideoSDK, \emph{Location Tracking with WebSocket}, 2024.

\bibitem{dotcom-monitor-tools}
Dotcom-Monitor, \emph{WebSocket Monitoring Tools}, 2024.

\bibitem{dotcom-monitor-metrics}
Dotcom-Monitor, \emph{WebSocket Monitoring Metrics}, 2024.

\bibitem{ably-websocket-conclusion}
Ably, \emph{The Future of Real-Time with WebSocket}, 2024.

\bibitem{anthropic-mcp}
Anthropic, \emph{Introducing Model Context Protocol}, 2024.

\bibitem{milvus-mcp}
Milvus, \emph{How Does MCP Differ from REST, GraphQL or gRPC}, 2024.

\bibitem{codica-mcp}
Codica, \emph{Model Context Protocol Explained}, 2024.

\bibitem{philschmid-mcp}
Philipp Schmid, \emph{MCP Introduction}, 2024.

\bibitem{auth0-mcp}
Auth0/Descope, \emph{Understanding MCP}, 2024.

\bibitem{bcg-mcp}
Boston Consulting Group, \emph{Put AI to Work Faster Using MCP}, 2024.

\bibitem{openreplay-mcp}
OpenReplay Blog, \emph{MCP vs GraphQL vs REST}, 2024.

\bibitem{philschmid-mcp-agents}
Philipp Schmid, \emph{Multi-Agent Orchestration with MCP}, 2024.

\bibitem{modelcontextprotocol}
Model Context Protocol Documentation, 2024.

\bibitem{bcg-automation}
Boston Consulting Group, \emph{Hyperautomation and Business Process}, 2024.

\bibitem{wikipedia-mcp}
Wikipedia, \emph{Model Context Protocol}, 2024.

\bibitem{codica-mcp-conclusion}
Codica, \emph{The Future of AI Agent Integration}, 2024.

\end{thebibliography}

\end{document}